# Flume e Kafka

![Flafka](media/flafkaLogo.png 'Flafka')

## Introdução

Neste trabalho prático de Processamento de Fluxos Discretos e Contínuos de Dados, vamos explorar o uso integrado das ferramentas Flume e Kafka para processamento de dados em tempo real.

### Kafka

O Apache Kafka é uma plataforma de streaming de dados usada para processar e transmitir informações em tempo real. Ele é muito eficiente para lidar com grandes volumes de dados e é amplamente utilizado em sistemas que necessitam de alta velocidade e confiabilidade na troca de informações. Kafka organiza os dados em "tópicos" e os divide em "partições", permitindo que várias aplicações possam processar os dados de maneira paralela. É usado em aplicações que vão desde análise de dados em tempo real até integração entre sistemas distribuídos.

### Flume

O Apache Flume é uma ferramenta que ajuda a mover dados de um lugar para outro de forma confiável. É útil para coletar informações de diferentes fontes, como arquivos de log ou sensores, e enviá-las para sistemas de armazenamento como Hadoop. É uma maneira eficiente de lidar com grandes quantidades de dados em ambientes de computação distribuída.

## Objetivos

## Experimentos

1. Inicializando a Máquina Virtual
![Inicializando a VM](media/initVM.png 'Inicializando a VM')
2. Inicializando Servidor Kafka
![Inicializando Kafka Server](media/initKafkaSrv.gif 'Inicializando Kafka Server')
3. Criar Tópico
4. Listar Tópico
5. Executar Producer e Inserir Strings
6. Executar Consumer
7. Flume
8. Flafka

## Conclusão
